[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Before we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(rgdal, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n\nNote: With tidyverse, we do not have to install readr, ggplot2 and dplyr packages separately. In fact, tidyverse also installs other very useful R packages such as tidyr."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-geospatial-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-geospatial-data-into-r-environment",
    "title": "Hands-on Exercise 6",
    "section": "2.1 Importing geospatial data into R environment",
    "text": "2.1 Importing geospatial data into R environment\nIn this section, you will import Myanmar Township Boundary GIS data and its associated attrbiute table into R environment.\nThe Myanmar Township Boundary GIS data is in ESRI shapefile format. It will be imported into R environment by using the st_read() function of sf.\nThe code chunks used are shown below:\n\nshan_sf &lt;- st_read(dsn = \"../../data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\wanshen123\\IS415-GAA\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nThe imported township boundary object is called shan_sf. It is saved in simple feature data.frame format. We can view the content of the newly created shan_sf simple features data.frame by using the code chunk below.\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nNotice that sf.data.frame is conformed to Hardy Wickham’s tidy framework.\nSince shan_sf is conformed to tidy framework, we can also glimpse() to reveal the data type of it’s fields.\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-aspatial-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-aspatial-data-into-r-environment",
    "title": "Hands-on Exercise 6",
    "section": "2.2 Importing aspatial data into R environment",
    "text": "2.2 Importing aspatial data into R environment\nThe csv file will be import using read_csv function of readr package.\nThe code chunks used are shown below:\n\nict &lt;- read_csv (\"../../data/aspatial/Shan-ICT.csv\")\n\nThe imported InfoComm variables are extracted from The 2014 Myanmar Population and Housing Census Myanmar. The attribute data set is called ict. It is saved in R’s * tibble data.frame* format.\nThe code chunk below reveal the summary statistics of ict data.frame.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nThere are a total of eleven fields and 55 observation in the tibble data.frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#derive-new-variables-using-dplyr-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#derive-new-variables-using-dplyr-package",
    "title": "Hands-on Exercise 6",
    "section": "2.3 Derive new variables using dplyr package",
    "text": "2.3 Derive new variables using dplyr package\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nLet us review the summary statistics of the newly derived penetration rates using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\nNotice that six new fields have been added into the data.frame. They are RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#eda-using-statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#eda-using-statistical-graphics",
    "title": "Hands-on Exercise 6",
    "section": "3.1 EDA using statistical graphics",
    "text": "3.1 EDA using statistical graphics\nWe can plot the distribution of the variables (i.e. Number of households with radio) by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution)\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\nNext, we will also plotting the distribution of the newly derived variables (i.e. Radio penetration rate) by using the code chunk below.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\nWhat can you observed from the distributions reveal in the histogram and boxplot.\nIn the figure below, multiple histograms are plotted to reveal the distribution of the selected variables in the ict_derived data.frame.\nThe code chunks below are used to create the data visualisation. They consist of two main parts. First, we will create the individual histograms using the code chunk below.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nNext, the ggarrange() function of ggpubr package is used to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#eda-using-choropleth-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#eda-using-choropleth-map",
    "title": "Hands-on Exercise 6",
    "section": "3.2 EDA using choropleth map",
    "text": "3.2 EDA using choropleth map\n\n3.2.1 Joining geospatial data with aspatial data\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"../../data/rds/shan_sf.rds\")\n\nThe message above shows that TS_CODE field is the common field used to perform the left-join.\nIt is important to note that there is no new output data been created. Instead, the data fields from ict_derived data frame are now updated into the data frame of shan_sf.\n\nshan_sf &lt;- read_rds(\"../../data/rds/shan_sf.rds\")\n\n\n\n3.2.2 Preparing a choropleth map\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\nIn order to reveal the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the dsitribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\nCan you identify the differences?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#extracting-clustering-variables",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#extracting-clustering-variables",
    "title": "Hands-on Exercise 6",
    "section": "5.1 Extracting clustering variables",
    "text": "5.1 Extracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\nNext, we need to change the rows by township name instead of row number by using the code chunk below\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the row number has been replaced into the township name.\nNow, we will delete the TS.x field by using the code chunk below.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-standardisation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-standardisation",
    "title": "Hands-on Exercise 6",
    "section": "5.2 Data Standardisation",
    "text": "5.2 Data Standardisation\nIn general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid the cluster analysis result is baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#min-max-standardisation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#min-max-standardisation",
    "title": "Hands-on Exercise 6",
    "section": "5.3 Min-Max standardisation",
    "text": "5.3 Min-Max standardisation\nIn the code chunk below, normalize() of heatmaply package is used to stadardisation the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nNotice that the values range of the Min-max standardised clustering variables are 0-1 now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#z-score-standardisation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#z-score-standardisation",
    "title": "Hands-on Exercise 6",
    "section": "5.4 Z-score standardisation",
    "text": "5.4 Z-score standardisation\nZ-score standardisation can be performed easily by using scale() of Base R. The code chunk below will be used to stadardisation the clustering variables by using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\nNote: describe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\nWarning: Z-score standardisation method should only be used if we would assume all variables come from some normal distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-the-standardised-clustering-variables",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-the-standardised-clustering-variables",
    "title": "Hands-on Exercise 6",
    "section": "5.5 Visualising the standardised clustering variables",
    "text": "5.5 Visualising the standardised clustering variables\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\nThe code chunk below plot the scaled Radio_PR field.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat statistical conclusion can you draw from the histograms above?\n\n\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-proximity-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-proximity-matrix",
    "title": "Hands-on Exercise 6",
    "section": "5.6 Computing proximity matrix",
    "text": "5.6 Computing proximity matrix\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\nThe code chunk below can then be used to list the content of proxmat for visual inspection.\n\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-hierarchical-clustering",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-hierarchical-clustering",
    "title": "Hands-on Exercise 6",
    "section": "5.7 Computing hierarchical clustering",
    "text": "5.7 Computing hierarchical clustering\nIn R, there are several packages provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used.\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the tree by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#selecting-the-optimal-clustering-algorithm",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#selecting-the-optimal-clustering-algorithm",
    "title": "Hands-on Exercise 6",
    "section": "5.8 Selecting the optimal clustering algorithm",
    "text": "5.8 Selecting the optimal clustering algorithm\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#determining-optimal-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#determining-optimal-clusters",
    "title": "Hands-on Exercise 6",
    "section": "5.9 Determining Optimal Clusters",
    "text": "5.9 Determining Optimal Clusters\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n5.9.1 Gap Statistic Method\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\nNote: In addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#interpreting-the-dendrograms",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#interpreting-the-dendrograms",
    "title": "Hands-on Exercise 6",
    "section": "5.10 Interpreting the dendrograms",
    "text": "5.10 Interpreting the dendrograms\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visually-driven-hierarchical-clustering-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visually-driven-hierarchical-clustering-analysis",
    "title": "Hands-on Exercise 6",
    "section": "5.11 Visually-driven hierarchical clustering analysis",
    "text": "5.11 Visually-driven hierarchical clustering analysis\nIn this section, we will learn how to perform visually-driven hiearchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n5.11.1 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n5.11.2 Plotting interactive cluster heatmap using heatmaply()\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#mapping-the-clusters-formed",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#mapping-the-clusters-formed",
    "title": "Hands-on Exercise 6",
    "section": "5.12 Mapping the clusters formed",
    "text": "5.12 Mapping the clusters formed\nWith closed examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nThe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the cluster formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#converting-into-spatialpolygonsdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#converting-into-spatialpolygonsdataframe",
    "title": "Hands-on Exercise 6",
    "section": "6.1 Converting into SpatialPolygonsDataFrame",
    "text": "6.1 Converting into SpatialPolygonsDataFrame\nFirst, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because SKATER function only support sp objects such as SpatialPolygonDataFrame.\nThe code chunk below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp &lt;- as_Spatial(shan_sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-neighbour-list",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-neighbour-list",
    "title": "Hands-on Exercise 6",
    "section": "6.2 Computing Neighbour List",
    "text": "6.2 Computing Neighbour List\nNext, poly2nd() of spdep package will be used to compute the neighbours list from polygon list.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe can plot the neighbours list on shan_sp by using the code chunk below. Since we now can plot the community area boundaries as well, we plot this graph on top of the map. The first plot command gives the boundaries. This is followed by the plot of the neighbor list object, with coordinates applied to the original SpatialPolygonDataFrame (Shan state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.\n\nplot(shan_sp, \n     border=grey(.5))\nplot(shan.nb, \n     coordinates(shan_sp), \n     col=\"blue\", \n     add=TRUE)\n\nNote that if you plot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-minimum-spanning-tree",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-minimum-spanning-tree",
    "title": "Hands-on Exercise 6",
    "section": "6.3 Computing minimum spanning tree",
    "text": "6.3 Computing minimum spanning tree\n\n6.3.1 Calculating edge costs\nNext, nbcosts() of spdep package is used to compute the cost of each edge. It is the distance between it nodes. This function compute this distance using a data.frame with observations vector in each node.\nThe code chunk below is used to compute the cost of each edge.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below.\nNote that we specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-minimum-spanning-tree-1",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-minimum-spanning-tree-1",
    "title": "Hands-on Exercise 6",
    "section": "6.4 Computing minimum spanning tree",
    "text": "6.4 Computing minimum spanning tree\nThe minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below.\n\nshan.mst &lt;- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunk below.\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(shan.mst)\n\n[1] 54  3\n\n\nNote that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(shan_sp, border=gray(.5))\nplot.mst(shan.mst, \n         coordinates(shan_sp), \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-spatially-constrained-clusters-using-skater-method",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-spatially-constrained-clusters-using-skater-method",
    "title": "Hands-on Exercise 6",
    "section": "6.5 Computing spatially constrained clusters using SKATER method",
    "text": "6.5 Computing spatially constrained clusters using SKATER method\nThe code chunk below compute the spatially constrained cluster using skater() of spdep package.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the conde chunk below.\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\nplot(shan_sp, border=gray(.5))\nplot(clust6, \n     coordinates(shan_sp), \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-the-clusters-in-choropleth-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-the-clusters-in-choropleth-map",
    "title": "Hands-on Exercise 6",
    "section": "6.6 Visualising the clusters in choropleth map",
    "text": "6.6 Visualising the clusters in choropleth map\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\nFor easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#a-short-note-about-clustgeo-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#a-short-note-about-clustgeo-package",
    "title": "Hands-on Exercise 6",
    "section": "7.1 A short note about ClustGeo package",
    "text": "7.1 A short note about ClustGeo package\nClustGeo package is an R package specially designed to support the need of performing spatially constrained cluster analysis. More specifically, it provides a Ward-like hierarchical clustering algorithm called hclustgeo() including spatial/geographical constraints.\nIn the nutshell, the algorithm uses two dissimilarity matrices D0 and D1 along with a mixing parameter alpha, whereby the value of alpha must be a real number between [0, 1]. D0 can be non-Euclidean and the weights of the observations can be non-uniform. It gives the dissimilarities in the attribute/clustering variable space. D1, on the other hand, gives the dissimilarities in the constraint space. The criterion minimised at each stage is a convex combination of the homogeneity criterion calculated with D0 and the homogeneity criterion calculated with D1.\nThe idea is then to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest. This need is supported by a function called choicealpha()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#ward-like-hierarchical-clustering-clustgeo",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#ward-like-hierarchical-clustering-clustgeo",
    "title": "Hands-on Exercise 6",
    "section": "7.2 Ward-like hierarchical clustering: ClustGeo",
    "text": "7.2 Ward-like hierarchical clustering: ClustGeo\nClustGeo package provides function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like hclust() you learned in previous section.\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist(). For sample code chunk, please refer to 5.7.6 Computing proximity matrix\n\n7.2.1 Mapping the clusters formed\nSimilarly, we can plot the clusters on a categorical area shaded map by using the steps we learned in 5.7.12 Mapping the clusters formed.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatially-constrained-hierarchical-clustering",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatially-constrained-hierarchical-clustering",
    "title": "Hands-on Exercise 6",
    "section": "7.3 Spatially Constrained Hierarchical Clustering",
    "text": "7.3 Spatially Constrained Hierarchical Clustering\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance() of sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\nNotice that as.dist() is used to convert the data frame into matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\nWith reference to the graphs above, alpha = 0.3 will be used as shown in the code chunk below.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.3)\n\nNext, cutree() is used to derive the cluster objecct.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\nWe will then join back the group list with shan_sf polygon feature data frame by using the code chunk below.\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-individual-clustering-variable",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-individual-clustering-variable",
    "title": "Hands-on Exercise 6",
    "section": "8.1 Visualising individual clustering variable",
    "text": "8.1 Visualising individual clustering variable\nCode chunk below is used to reveal the distribution of a clustering variable (i.e RADIO_PR) by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#multivariate-visualisation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#multivariate-visualisation",
    "title": "Hands-on Exercise 6",
    "section": "8.2 Multivariate Visualisation",
    "text": "8.2 Multivariate Visualisation\nPast studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. In the code chunk below, ggparcoord() of GGally package\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nNote that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThere is no one best scaling method to use. You should explore them and select the one that best meet your analysis need.\nLast but not least, we can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "Background\nIn this study, our focus will be on investigating whether the distribution of dengue fever outbreaks in Tainan City, Taiwan, is independent of spatial and temporal factors. If the outbreak exhibits spatial and spatio-temporal dependencies, our goal is to pinpoint clusters, outliers, and emerging hot spot/cold spot areas within the region.\nPackages Used:\n\nsf: For importing, managing, and processing geospatial data.\ntidyverse: Collection of packages for data science tasks.\ntmap: For creating thematic maps, such as choropleth and bubble maps.\nsfdep: Creating an sf and tidyverse friendly interface.\n\n\npacman::p_load(sf, sfdep, tmap, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-spatial-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-spatial-data",
    "title": "Take-home Exercise 2",
    "section": "2.1 Importing the spatial data",
    "text": "2.1 Importing the spatial data\nAspatial Data\n\ndengueDaily &lt;- read_csv(\"../../data/TakeHome/TakeHome_02/aspatial/Dengue_Daily.csv\")\n\nGeospatial Data\n\ntainan &lt;- st_read(dsn = \"../../data/TakeHome/TakeHome_02/geospatial\", \n                 layer = \"TAINAN_VILLAGE\")\n\nReading layer `TAINAN_VILLAGE' from data source \n  `C:\\wanshen123\\IS415-GAA\\data\\TakeHome\\TakeHome_02\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 649 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0269 ymin: 22.88751 xmax: 120.6563 ymax: 23.41374\nGeodetic CRS:  TWD97\n\nhead(tainan, 3)\n\nSimple feature collection with 3 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0936 ymin: 22.93251 xmax: 120.2905 ymax: 23.13561\nGeodetic CRS:  TWD97\n     VILLCODE COUNTYNAME TOWNNAME VILLNAME      VILLENG COUNTYID COUNTYCODE\n1 67000280002     臺南市   歸仁區   六甲里  Liujia Vil.        D      67000\n2 67000350032     臺南市   安南區   青草里 Qingcao Vil.        D      67000\n3 67000150009     臺南市   七股區   溪南里   Xinan Vil.        D      67000\n  TOWNID TOWNCODE NOTE                       geometry\n1    D33 67000280 &lt;NA&gt; POLYGON ((120.2725 22.95868...\n2    D06 67000350 &lt;NA&gt; POLYGON ((120.1176 23.08387...\n3    D22 67000150 &lt;NA&gt; POLYGON ((120.121 23.1355, ..."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-pre-processing",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-pre-processing",
    "title": "Take-home Exercise 2",
    "section": "2.2 Data Pre-Processing",
    "text": "2.2 Data Pre-Processing\n\n2.2.1 Retrieve D01, D02, D04, D06, D07, D08, D32 and D39 counties of Tainan City, Taiwan.\n\nfiltered_tainan &lt;- tainan[tainan$TOWNID %in% c(\"D01\", \"D02\", \"D04\", \"D06\", \"D07\", \"D08\", \"D32\", \"D39\"), ]\n\n\n\n2.2.2 Dengue fever cases confined to epidemiology week 31-50, 2023\n\n\n\n\n\n\nNote\n\n\n\nConvert date column to Date format if it’s not already\n\n\n\ndengueDaily$發病日 &lt;- as.Date(dengueDaily$發病日)\n#dengueDaily$通報日 &lt;- as.Date(dengueDaily$通報日)\n\nExtract week numbers from the date column\n\ndengueDaily$week_number_onsetDay &lt;- as.numeric(format(dengueDaily$發病日, \"%V\"))\n#dengueDaily$week_number_reportDay &lt;- as.numeric(format(dengueDaily$通報日, \"%V\"))\n\nDefine the start (31) and end (50) weeks of your range\n\nonset_start_week &lt;- 31\nonset_end_week &lt;- 50\n#report_start_week &lt;- 31\n#report_end_week &lt;- 50\n\nDefine the year\n\nyear &lt;- 2023\n\nFilter rows based on the week range\n\nfiltered_dengue &lt;- dengueDaily[dengueDaily$week_number_onsetDay &gt;= onset_start_week & dengueDaily$week_number_onsetDay &lt;= onset_end_week & year(dengueDaily$發病日) == year, ]\n#filtered_reportDengue &lt;- dengueDaily[dengueDaily$week_number_reportDay &gt;= report_start_week & dengueDaily$week_number_reportDay &lt;= report_end_week & year(dengueDaily$通報日) == year, ]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-cleaning",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-cleaning",
    "title": "Take-home Exercise 2",
    "section": "2.3 Data Cleaning",
    "text": "2.3 Data Cleaning\nTranslate to English\n\nfiltered_dengue &lt;- filtered_dengue %&gt;%\n  rename('x-coordinate' = 最小統計區中心點X,\n         'y-coordinate' = 最小統計區中心點Y,\n         'COUNTYNAME' = 居住縣市,\n         'VILLNAME' = 居住村里,\n         'TOWNNAME' = 居住鄉鎮)\n\nCheck the current class of the column\n\nclass(filtered_dengue$`x-coordinate`)\n\n[1] \"character\"\n\nclass(filtered_dengue$`y-coordinate`)\n\n[1] \"character\"\n\n\nConvert the column to numeric\n\nfiltered_dengue$`x-coordinate` &lt;- as.numeric(filtered_dengue$`x-coordinate`)\nfiltered_dengue$`y-coordinate` &lt;- as.numeric(filtered_dengue$`y-coordinate`)\n\nCheck the class of the column after conversion\n\nclass(filtered_dengue$`x-coordinate`)\n\n[1] \"numeric\"\n\nclass(filtered_dengue$`y-coordinate`)\n\n[1] \"numeric\"\n\n\nRemove NA values from all columns\n\nfiltered_dengue &lt;- na.omit(filtered_dengue)\n\nGrouping village based on number of dengue cases\n\ngrouped_data &lt;- filtered_dengue %&gt;%\n  group_by(VILLNAME, week_number_onsetDay) %&gt;%\n  summarise(dengueCases = sum(確定病例數))\n\nRemoving missing values\n\ngrouped_data &lt;- grouped_data[!(grouped_data$VILLNAME == \"None\"), ]\n\nCombining both data frame by using left join\n\njoined_data &lt;- left_join(filtered_tainan, grouped_data, by = c(\"VILLNAME\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plotting-a-choropleth-map",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plotting-a-choropleth-map",
    "title": "Take-home Exercise 2",
    "section": "2.4 Plotting a choropleth map",
    "text": "2.4 Plotting a choropleth map\nBefore removing missing values\n\ntmap_mode(\"plot\")\ntm_shape(joined_data) +\n  tm_fill(\"dengueCases\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dengue Cases\") +\n  tm_layout(main.title = \"Distribution of Dengue Cases\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nMissing values means that the dengue cases are not part of the selected counties.\n\n\nTo fill missing values (NA) with 0\n\njoined_data$dengueCases[is.na(joined_data$dengueCases)] &lt;- 0\n\nAfter removing missing values\n\nAugustSeptemberOctoberNovemberDecember\n\n\n\naugust &lt;- joined_data %&gt;%\n  filter(week_number_onsetDay &gt;= 31 & week_number_onsetDay &lt;= 35)\ntmap_mode(\"plot\")\ntm_shape(august) +\n  tm_fill(\"dengueCases\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dengue Cases\") +\n  tm_layout(main.title = \"August 2023 Distribution of Dengue Cases\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\n\n\nseptember &lt;- joined_data %&gt;%\n  filter(week_number_onsetDay &gt;= 36 & week_number_onsetDay &lt;= 39)\ntmap_mode(\"plot\")\ntm_shape(september) +\n  tm_fill(\"dengueCases\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dengue Cases\") +\n  tm_layout(main.title = \"September 2023 Distribution of Dengue Cases\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\n\n\noctober &lt;- joined_data %&gt;%\n  filter(week_number_onsetDay &gt;= 40 & week_number_onsetDay &lt;= 44)\ntmap_mode(\"plot\")\ntm_shape(october) +\n  tm_fill(\"dengueCases\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dengue Cases\") +\n  tm_layout(main.title = \"October 2023 Distribution of Dengue Cases\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\n\n\nnovember &lt;- joined_data %&gt;%\n  filter(week_number_onsetDay &gt;= 45 & week_number_onsetDay &lt;= 48)\ntmap_mode(\"plot\")\ntm_shape(november) +\n  tm_fill(\"dengueCases\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dengue Cases\") +\n  tm_layout(main.title = \"November 2023 Distribution of Dengue Cases\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\n\n\ndecember &lt;- joined_data %&gt;%\n  filter(week_number_onsetDay &gt;= 49 & week_number_onsetDay &lt;= 50)\ntmap_mode(\"plot\")\ntm_shape(december) +\n  tm_fill(\"dengueCases\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dengue Cases\") +\n  tm_layout(main.title = \"December 2023 Distribution of Dengue Cases\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAreas that are white in colour are those that have no dengue cases."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#deriving-contiguity-weights-queens-method",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#deriving-contiguity-weights-queens-method",
    "title": "Take-home Exercise 2",
    "section": "3.1 Deriving contiguity weights: Queen’s method",
    "text": "3.1 Deriving contiguity weights: Queen’s method\nWe compute spatial contiguity relationships among geometries stored in a data frame, calculates spatial weights based on these relationships, and adds the resulting variables to the data frame.\n\n\n\n\n\n\nNote\n\n\n\nResetting the joined_data to the original data frame\n\n\n\ngrouped_data &lt;- filtered_dengue %&gt;%\n  group_by(VILLNAME) %&gt;%\n  summarise(dengueCases = sum(確定病例數))\ngrouped_data &lt;- grouped_data[!(grouped_data$VILLNAME == \"None\"), ]\njoined_data &lt;- left_join(filtered_tainan, grouped_data, by = c(\"VILLNAME\"))\njoined_data$dengueCases[is.na(joined_data$dengueCases)] &lt;- 0\n\n\nwm_q &lt;- joined_data %&gt;%\n  mutate(nb = st_contiguity(geometry, queen=TRUE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nExamining the contents of the spatial weights matrix\n\nglimpse(wm_q)\n\nRows: 258\nColumns: 14\n$ nb          &lt;nb&gt; &lt;6, 118, 160&gt;, &lt;126, 128, 138, 168, 222&gt;, &lt;68, 69, 172, 181…\n$ wt          &lt;list&gt; &lt;0.3333333, 0.3333333, 0.3333333&gt;, &lt;0.2, 0.2, 0.2, 0.2, 0…\n$ VILLCODE    &lt;chr&gt; \"67000350032\", \"67000270011\", \"67000370005\", \"67000330004\"…\n$ COUNTYNAME  &lt;chr&gt; \"臺南市\", \"臺南市\", \"臺南市\", \"臺南市\", \"臺南市\", \"臺南市\"…\n$ TOWNNAME    &lt;chr&gt; \"安南區\", \"仁德區\", \"中西區\", \"南區\", \"安南區\", \"安南區\", …\n$ VILLNAME    &lt;chr&gt; \"青草里\", \"保安里\", \"赤嵌里\", \"大成里\", \"城北里\", \"城南里\"…\n$ VILLENG     &lt;chr&gt; \"Qingcao Vil.\", \"Bao'an Vil.\", \"Chihkan Vil.\", \"Dacheng Vi…\n$ COUNTYID    &lt;chr&gt; \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\"…\n$ COUNTYCODE  &lt;chr&gt; \"67000\", \"67000\", \"67000\", \"67000\", \"67000\", \"67000\", \"670…\n$ TOWNID      &lt;chr&gt; \"D06\", \"D32\", \"D08\", \"D02\", \"D06\", \"D06\", \"D08\", \"D06\", \"D…\n$ TOWNCODE    &lt;chr&gt; \"67000350\", \"67000270\", \"67000370\", \"67000330\", \"67000350\"…\n$ NOTE        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ dengueCases &lt;dbl&gt; 2, 33, 111, 29, 6, 13, 37, 48, 108, 66, 26, 2, 5, 11, 24, …\n$ geometry    &lt;POLYGON [°]&gt; POLYGON ((120.1176 23.08387..., POLYGON ((120.2304…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-global-morans-i",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-global-morans-i",
    "title": "Take-home Exercise 2",
    "section": "3.2 Computing Global Moran’s I",
    "text": "3.2 Computing Global Moran’s I\nWe compute the global Moran’s I statistic to test for spatial autocorrelation in the data.\n\nmoranI &lt;- global_moran(wm_q$dengueCases,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.397\n $ K: num 4.83"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#performing-global-morans-i-test",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#performing-global-morans-i-test",
    "title": "Take-home Exercise 2",
    "section": "3.3 Performing Global Moran’s I test",
    "text": "3.3 Performing Global Moran’s I test\nGlobal_moran_test() performs the Moran’s I test, which assesses whether there is spatial autocorrelation in the variable represented by wm_q\\(count. The contiguity relationship matrix (wm_q\\)nb) and the corresponding spatial weights (wm_q$wt) are used to compute Moran’s I statistic and its associated p-value. This helps to determine if the observed spatial pattern is significantly different from what would be expected under spatial randomness.\n\nglobal_moran_test(wm_q$dengueCases,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 10.902, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.396838835      -0.003891051       0.001351108"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#performing-global-morans-i-permutation-test",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#performing-global-morans-i-permutation-test",
    "title": "Take-home Exercise 2",
    "section": "3.4 Performing Global Moran’s I permutation test",
    "text": "3.4 Performing Global Moran’s I permutation test\nIn practical applications, it’s advisable to utilize Monte Carlo simulation when conducting statistical tests. For the sfdep package, this functionality is facilitated through the globel_moran_perm() function.\nTo maintain reproducibility in the simulation process, it’s recommended to employ set.seed() before conducting the simulation. This ensures that the computational results are consistent and reproducible across different runs.\n\nset.seed(1234)\n\nNext, global_moran_perm() is used to perform Monte Carlo simulation.\n\nglobal_moran_perm(wm_q$dengueCases,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.39684, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe statistical report above show that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of dengue cases per counties resemble random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-local-morans-i",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-local-morans-i",
    "title": "Take-home Exercise 2",
    "section": "4.1 Computing local Moran’s I",
    "text": "4.1 Computing local Moran’s I\nLocal_moran() computes the local Moran’s I statistic to test for spatial autocorrelation in the data. The contiguity relationship matrix (wm_q\\(nb) and the corresponding spatial weights (wm_q\\)wt) are used to compute the local Moran’s I statistic and its associated p-value. This helps to determine if the observed spatial pattern is significantly different from what would be expected under spatial randomness.\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    dengueCases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-local-morans-i",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-local-morans-i",
    "title": "Take-home Exercise 2",
    "section": "4.2 Visualising local Moran’s I",
    "text": "4.2 Visualising local Moran’s I\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the ii field.\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Dengue Cases\",\n            main.title.size = 0.8)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-p-value-of-local-morans-i",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-p-value-of-local-morans-i",
    "title": "Take-home Exercise 2",
    "section": "4.3 Visualising p-value of local Moran’s I",
    "text": "4.3 Visualising p-value of local Moran’s I\nIn the code chunk below, tmap functions are used prepare a choropleth map by using value in the p_ii_sim field.\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visuaising-local-morans-i-and-p-value",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visuaising-local-morans-i-and-p-value",
    "title": "Take-home Exercise 2",
    "section": "4.4 Visuaising local Moran’s I and p-value",
    "text": "4.4 Visuaising local Moran’s I and p-value\nFor effective comparison, it will be better for us to plot both maps next to each other as shown below.\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Dengue Cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-lisa-map",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-lisa-map",
    "title": "Take-home Exercise 2",
    "section": "4.5 Visualising LISA map",
    "text": "4.5 Visualising LISA map\nThe LISA map is a categorical representation revealing both outliers and clusters within a dataset. It identifies two kinds of outliers: High-Low and Low-High. Similarly, it highlights two types of clusters: High-High and Low-Low. Essentially, the LISA map is derived by integrating local Moran’s I values of geographical regions along with their corresponding p-values.\nWithin the lisa sf data frame, three fields encompass the LISA categories: mean, median, and pysal. Typically, the mean classification is preferred, as illustrated in the following code snippet.\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-gi",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-gi",
    "title": "Take-home Exercise 2",
    "section": "6.1 Visualising Gi*",
    "text": "6.1 Visualising Gi*\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-p-value-of-hcsa",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-p-value-of-hcsa",
    "title": "Take-home Exercise 2",
    "section": "6.2 Visualising p-value of HCSA",
    "text": "6.2 Visualising p-value of HCSA\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visuaising-local-hcsa",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visuaising-local-hcsa",
    "title": "Take-home Exercise 2",
    "section": "6.3 Visuaising local HCSA",
    "text": "6.3 Visuaising local HCSA\nFor effective comparison, it will be better for us to plot both maps next to each other as shown below.\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#creating-a-time-series-cube",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#creating-a-time-series-cube",
    "title": "Take-home Exercise 2",
    "section": "8.1 Creating a Time Series Cube",
    "text": "8.1 Creating a Time Series Cube\nA time series cube is a data structure that contains a series of spatial data layers, each representing the spatial distribution of a phenomenon at a specific point in time. In this case, we will create a time series cube containing the number of dengue fever cases in Tainan City, Taiwan, for each week of the year 2023.\n\ntest &lt;- filtered_dengue %&gt;%\n  group_by(發病日, VILLNAME) %&gt;%\n  summarise(count = sum(確定病例數))\n\n\ntest &lt;- test[!(test$VILLNAME == \"None\"), ]\n\n\ntest_join &lt;- left_join(filtered_tainan, test, by = c(\"VILLNAME\"))\n\n\ntest_join &lt;- test_join[!(test_join$count == \"NA\"), ]\n\n\ndengue_st &lt;- spacetime(test_join, filtered_tainan,\n                      .loc_col = \"VILLCODE\",\n                      .time_col = \"發病日\")\n\nNext, is_spacetime_cube() of sfdep package will be used to verify if dengue_st is indeed an space-time cube object.\n\nspt_complete &lt;- complete_spacetime_cube(dengue_st)\nis_spacetime_cube(spt_complete)\n\n[1] TRUE"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-gi",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-gi",
    "title": "Take-home Exercise 2",
    "section": "8.2 Computing Gi*",
    "text": "8.2 Computing Gi*\nNext, we will compute the local Gi* statistics.\n\n8.2.1 Deriving the spatial weights\nThe code chunk below will be used to identify neighbors and to derive an inverse distance weights."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding a space-time cube,\nCalculating Getis-Ord local Gi* statistic for each bin by using an FDR correction,\nEvaluating these hot and cold spot trends by using Mann-Kendall trend test,\nCategorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin.\n\n\n\nAs usual, p_load() of pacman package will be used to check if the necessary packages have been installed in R, if yes, load the packages on R environment.\nFive R packages are need for this in-class exercise, they are: sf, sfdep, tmap, and tidyverse.\n\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-r-packages",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "As usual, p_load() of pacman package will be used to check if the necessary packages have been installed in R, if yes, load the packages on R environment.\nFive R packages are need for this in-class exercise, they are: sf, sfdep, tmap, and tidyverse.\n\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-geospatial-data",
    "title": "In-class Exercise 6",
    "section": "2.1 Importing geospatial data",
    "text": "2.1 Importing geospatial data\nIn the code chunk below, st_read() of sf package is used to import Hunan shapefile into R.\n\nhunan &lt;- st_read(dsn = \"../../data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source `C:\\wanshen123\\IS415-GAA\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-attribute-table",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-attribute-table",
    "title": "In-class Exercise 6",
    "section": "2.2 Importing attribute table",
    "text": "2.2 Importing attribute table\nIn the code chunk below, read_csv() of readr is used to import Hunan_GDPPC.csv into R.\n\nGDPPC &lt;- read_csv(\"../../data/aspatial/Hunan_GDPPC.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-gi",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-gi",
    "title": "In-class Exercise 6",
    "section": "3.1 Computing Gi*",
    "text": "3.1 Computing Gi*\nNext, we will compute the local Gi* statistics.\n\n3.1.1 Deriving the spatial weights\nThe code chunk below will be used to identify neighbors and to derive an inverse distance weights.\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nactivate() of dplyr package is used to activate the geometry context\nmutate() of dplyr package is used to create two new columns nb and wt.\nThen we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts()\n\nrow order is very important so do not rearrange the observations after using set_nbs() or set_wts().\n\n\n\n\nNote that this dataset now has neighbors and weights for each time-slice.\n\nhead(GDPPC_nb)\n\n# A tibble: 6 × 5\n   Year County  GDPPC nb        wt       \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;   \n1  2005 Anxiang  8184 &lt;int [6]&gt; &lt;dbl [6]&gt;\n2  2005 Hanshou  6560 &lt;int [6]&gt; &lt;dbl [6]&gt;\n3  2005 Jinshi   9956 &lt;int [5]&gt; &lt;dbl [5]&gt;\n4  2005 Li       8394 &lt;int [5]&gt; &lt;dbl [5]&gt;\n5  2005 Linli    8850 &lt;int [5]&gt; &lt;dbl [5]&gt;\n6  2005 Shimen   9244 &lt;int [6]&gt; &lt;dbl [6]&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-gi-1",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-gi-1",
    "title": "In-class Exercise 6",
    "section": "3.2 Computing Gi*",
    "text": "3.2 Computing Gi*\nWe can use these new columns to manually calculate the local Gi* for each location. We can do this by grouping by Year and using local_gstar_perm() of sfdep package. After which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame.\n\ngi_stars &lt;- GDPPC_nb %&gt;% \n  group_by(Year) %&gt;% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#arrange-to-show-significant-emerging-hotcold-spots",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#arrange-to-show-significant-emerging-hotcold-spots",
    "title": "In-class Exercise 6",
    "section": "4.1 Arrange to show significant emerging hot/cold spots",
    "text": "4.1 Arrange to show significant emerging hot/cold spots\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#performing-emerging-hotspot-analysis",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#performing-emerging-hotspot-analysis",
    "title": "In-class Exercise 6",
    "section": "4.2 Performing Emerging Hotspot Analysis",
    "text": "4.2 Performing Emerging Hotspot Analysis\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object x (i.e. GDPPC_st), and the quoted name of the variable of interest (i.e. GDPPC) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st, \n  .var = \"GDPPC\", \n  k = 1, \n  nsim = 99\n)\n\n\n4.2.1 Visualising the distribution of EHSA classes\nIn the code chunk below, ggplot2 functions ised used to reveal the distribution of EHSA classes as a bar chart.\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\nFigure above shows that sporadic cold spots class has the high numbers of county.\n\n\n4.2.2 Visualising EHSA\nIn this section, you will learn how to visualise the geographic distribution EHSA classes. However, before we can do so, we need to join both hunan and ehsa together by using the code chunk below.\n\nhunan_ehsa &lt;- hunan %&gt;%\n  left_join(ehsa,\n            by = join_by(County == location))\n\nNext, tmap functions will be used to plot a categorical choropleth map by using the code chunk below.\n\nehsa_sig &lt;- hunan_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)\nhunan &lt;- st_read(dsn = \"../../data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source `C:\\wanshen123\\IS415-GAA\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nhunan2012 &lt;- read_csv(\"../../data/aspatial/Hunan_2012.csv\")\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n    select(1:4, 7, 15)\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\nlongitude &lt;- map_dbl(hunan$geometry,~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry,~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch=19, cex=0.6, add=TRUE, col=\"red\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#working-with-geographically-weighted-summary-statistics-gwss",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#working-with-geographically-weighted-summary-statistics-gwss",
    "title": "In-class Exercise 4",
    "section": "Working with Geographically Weighted Summary Statistics (GWSS)",
    "text": "Working with Geographically Weighted Summary Statistics (GWSS)\n\nhunan_sp &lt;- hunan %&gt;%\n  as_Spatial()\n\n\n#Adaptive = True, bw = 6 Neighbors. Adaptive = False, bw = 62 KM.\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = 6,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "This in-class introduces an alternative R package to spdep package you used in Chapter 9: Global Measures of Spatial Autocorrelation and Chapter 10: Local Measures of Spatial Autocorrelation. The package is called sfdep. According to Josiah Parry, the developer of the package, “sfdep builds on the great shoulders of spdep package for spatial dependence. sfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep. sfdep utilizes list columns extensively to make this interface possible.”\n\n\nFour R packages will be used for this in-class exercise, they are: sf, sfdep, tmap and tidyverse.\n\npacman::p_load(sf, sfdep, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#installing-and-loading-the-r-packages",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "Four R packages will be used for this in-class exercise, they are: sf, sfdep, tmap and tidyverse.\n\npacman::p_load(sf, sfdep, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-geospatial-data",
    "title": "In-class Exercise 5",
    "section": "2.1 Importing geospatial data",
    "text": "2.1 Importing geospatial data\n\nhunan &lt;- st_read(dsn = \"../../data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source `C:\\wanshen123\\IS415-GAA\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-attribute-table",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-attribute-table",
    "title": "In-class Exercise 5",
    "section": "2.1 Importing attribute table",
    "text": "2.1 Importing attribute table\n\nhunan2012 &lt;- read_csv(\"../../data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#combining-both-data-frame-by-using-left-join",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#combining-both-data-frame-by-using-left-join",
    "title": "In-class Exercise 5",
    "section": "2.2 Combining both data frame by using left join",
    "text": "2.2 Combining both data frame by using left join\n\nhunan_GDPPC &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plotting-a-choropleth-map",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plotting-a-choropleth-map",
    "title": "In-class Exercise 5",
    "section": "2.3 Plotting a choropleth map",
    "text": "2.3 Plotting a choropleth map\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#deriving-contiguity-weights-queens-method",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#deriving-contiguity-weights-queens-method",
    "title": "In-class Exercise 5",
    "section": "3.1 Deriving contiguity weights: Queen’s method",
    "text": "3.1 Deriving contiguity weights: Queen’s method\n\n\n\n\n\n\nNote\n\n\n\n.before means column is placed at column 1\n\n\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry, queen=TRUE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nNotice that st_weights() provides tree arguments, they are:\n\nnb: A neighbor list object as created by st_neighbors().\nstyle: Default “W” for row standardized weights. This value can also be “B”, “C”, “U”, “minmax”, and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nallow_zero: If TRUE, assigns zero as lagged value to zone without neighbors.\n\n\nwm_q\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-global-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-global-morans-i",
    "title": "In-class Exercise 5",
    "section": "3.2 Computing Global Moran’s I",
    "text": "3.2 Computing Global Moran’s I\nIn the code chunk below, global_moran() function is used to compute the Moran’s I value. Different from sdep package, the output is a tibble data.frame.\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-global-morans-i-test",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-global-morans-i-test",
    "title": "In-class Exercise 5",
    "section": "3.3 Performing Global Moran’s I test",
    "text": "3.3 Performing Global Moran’s I test\nIn general, Moran’s I test will be performed instead of just computing the Moran’s I statistics. With sfdep package, Moran’s I test can be performed by using global_moran_test() as shown in the code chunk below.\n\nglobal_moran_test(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-global-morans-i-permutation-test",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-global-morans-i-permutation-test",
    "title": "In-class Exercise 5",
    "section": "3.4 Performing Global Moran’s I permutation test",
    "text": "3.4 Performing Global Moran’s I permutation test\nIn practice, monte carlo simulation should be used to perform the statistical test. For sfdep, it is supported by globel_moran_perm()\nIt is alway a good practice to use set.seed() before performing simulation. This is to ensure that the computation is reproducible.\n\nset.seed(1234)\n\nNext, global_moran_perm() is used to perform Monte Carlo simulation.\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe statistical report above show that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of GDP per capital are resemble random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering.\n\n\n\n\n\n\nReminder\n\n\n\nThe numbers of simulation is always equal to nsim + 1. This mean in nsim = 99, This mean 100 simulation will be performed."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-local-morans-i",
    "title": "In-class Exercise 5",
    "section": "4.1 Visualising local Moran’s I",
    "text": "4.1 Visualising local Moran’s I\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the ii field.\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-p-value-of-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-p-value-of-local-morans-i",
    "title": "In-class Exercise 5",
    "section": "4.2 Visualising p-value of local Moran’s I",
    "text": "4.2 Visualising p-value of local Moran’s I\nIn the code chunk below, tmap functions are used prepare a choropleth map by using value in the p_ii_sim field.\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nFor p-values, the appropriate classification should be 0.001, 0.01, 0.05 and not significant instead of using default classification scheme."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visuaising-local-morans-i-and-p-value",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visuaising-local-morans-i-and-p-value",
    "title": "In-class Exercise 5",
    "section": "4.3 Visuaising local Moran’s I and p-value",
    "text": "4.3 Visuaising local Moran’s I and p-value\nFor effective comparison, it will be better for us to plot both maps next to each other as shown below.\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-lisa-map",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-lisa-map",
    "title": "In-class Exercise 5",
    "section": "4.4 Visualising LISA map",
    "text": "4.4 Visualising LISA map\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values.\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are mean, median and pysal. In general, classification in mean will be used as shown in the code chunk below.\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-gi",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-gi",
    "title": "In-class Exercise 5",
    "section": "6.1 Visualising Gi*",
    "text": "6.1 Visualising Gi*\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-p-value-of-hcsa",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-p-value-of-hcsa",
    "title": "In-class Exercise 5",
    "section": "6.2 Visualising p-value of HCSA",
    "text": "6.2 Visualising p-value of HCSA\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visuaising-local-hcsa",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visuaising-local-hcsa",
    "title": "In-class Exercise 5",
    "section": "6.3 Visuaising local HCSA",
    "text": "6.3 Visuaising local HCSA\nFor effective comparison, you can plot both maps next to each other as shown below.\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Background\nIn this study, we examine the spatial and temporal spread of Grab ride-hailing services in Singapore, utilizing the extensive dataset offered by Grab, known as Grab Posisi. As a prominent provider of shared taxi services in Southeast Asia, Grab’s dataset provides valuable insights into human mobility. Our research concentrates on employing Spatial Point Pattern Analyses (KDE/NKDE) to uncover underlying patterns within this dataset.\nPackages Used:\n\nsf: For importing, managing, and processing geospatial data.\ntidyverse: Collection of packages for data science tasks.\ntmap: For creating thematic maps, such as choropleth and bubble maps.\nspatstat: For point pattern analysis.\nraster: Reads, writes, manipulates, analyses and models gridded spatial data.\nmaptools: A set of tools for manipulating geographic data.\nclassInt: Selected commonly used methods for choosing univariate class intervals for mapping or other graphics purposes.\nspNetwork: Perform spatial analysis on network.\nviridis: Make plots that are pretty, better represent your data and easier to read by those with colorblindness.\narrow: Work with parquet files and to load the GrabPosisi dataset.\n\n\npacman::p_load(sf, tidyverse, tmap, maptools, raster, spatstat, spNetwork, classInt, viridis, arrow)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-spatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-spatial-data",
    "title": "Take-home Exercise 1",
    "section": "2.1 Importing the spatial data",
    "text": "2.1 Importing the spatial data\nAspatial Data\n\ngrab0 &lt;- read_parquet(\"../../data/TakeHome/TakeHome_01/aspatial/part-00000.parquet\") \ngrab1 &lt;- read_parquet(\"../../data/TakeHome/TakeHome_01/aspatial/part-00001.parquet\")\ngrab2 &lt;- read_parquet(\"../../data/TakeHome/TakeHome_01/aspatial/part-00002.parquet\")\ngrab3 &lt;- read_parquet(\"../../data/TakeHome/TakeHome_01/aspatial/part-00003.parquet\")\ngrab4 &lt;- read_parquet(\"../../data/TakeHome/TakeHome_01/aspatial/part-00004.parquet\")\ngrab5 &lt;- read_parquet(\"../../data/TakeHome/TakeHome_01/aspatial/part-00005.parquet\")\ngrab6 &lt;- read_parquet(\"../../data/TakeHome/TakeHome_01/aspatial/part-00006.parquet\")\ngrab7 &lt;- read_parquet(\"../../data/TakeHome/TakeHome_01/aspatial/part-00007.parquet\")\ngrab8 &lt;- read_parquet(\"../../data/TakeHome/TakeHome_01/aspatial/part-00008.parquet\")\ngrab9 &lt;- read_parquet(\"../../data/TakeHome/TakeHome_01/aspatial/part-00009.parquet\")\n\nGeospatial Data\n\nroadMe &lt;- st_read(\"../../data/TakeHome/TakeHome_01/geospatial\",\n               layer = \"gis_osm_roads_free_1\")\nhead(roadMe, n=3)\n\n\nislandMe &lt;- st_read(dsn=\"../../data/TakeHome/TakeHome_01/geospatial\", layer=\"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\wanshen123\\IS415-GAA\\data\\TakeHome\\TakeHome_01\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nhead(islandMe, n=3)\n\nSimple feature collection with 3 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.8303 ymin: 1.280459 xmax: 103.8811 ymax: 1.296311\nGeodetic CRS:  WGS 84\n         SUBZONE_N SUBZONE_C      PLN_AREA_N PLN_AREA_C       REGION_N REGION_C\n1      MARINA EAST    MESZ01     MARINA EAST         ME CENTRAL REGION       CR\n2 INSTITUTION HILL    RVSZ05    RIVER VALLEY         RV CENTRAL REGION       CR\n3   ROBERTSON QUAY    SRSZ01 SINGAPORE RIVER         SR CENTRAL REGION       CR\n                        geometry\n1 MULTIPOLYGON (((103.8802 1....\n2 MULTIPOLYGON (((103.8376 1....\n3 MULTIPOLYGON (((103.8341 1...."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-pre-processing",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-pre-processing",
    "title": "Take-home Exercise 1",
    "section": "2.2 Data Pre-Processing",
    "text": "2.2 Data Pre-Processing\nRemove rows with missing values\n\nroad_df &lt;- roadMe[!(is.na(roadMe$name)), ]\nisland_df &lt;- islandMe[!(is.na(islandMe$geometry)), ]\n\nCombine all grab data into one\n\nmerged_data &lt;- bind_rows(grab0, grab1, grab2, grab3, grab4, grab5, grab6, grab7, grab8, grab9)\n\nFormatting pingtimestamp into date & time\n\nmerged_data$pingtimestamp &lt;- as_datetime(merged_data$pingtimestamp)\n\nRetrieve all origin locations data\n\norigin_df &lt;- merged_data %&gt;% \n  group_by(trj_id) %&gt;%\n  arrange(pingtimestamp) %&gt;%\n  filter(row_number()==1) %&gt;%\n  mutate(weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\norigin_df\n\nRetrieve all destination locations data\n\ndestination_df &lt;- merged_data %&gt;% \n  group_by(trj_id) %&gt;%\n  arrange(desc(pingtimestamp)) %&gt;%\n  filter(row_number()==1) %&gt;%\n  mutate(weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         end_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\ndestination_df\n\n\nroad_df &lt;- read_rds(\"../../data/TakeHome/TakeHome_01/rds/road_df.rds\")\nisland_df &lt;- read_rds(\"../../data/TakeHome/TakeHome_01/rds/island_df.rds\")\n\n\norigin_df &lt;- read_rds(\"../../data/TakeHome/TakeHome_01/rds/origin_df.rds\")\ndestination_df &lt;- read_rds(\"../../data/TakeHome/TakeHome_01/rds/destination_df.rds\")\n\n\n\n\n\n\n\nNote\n\n\n\nUsing the crs info function to retrieve the referencing system information of these geospatial data.\n\n\n\ncrs_info1 &lt;- st_crs(road_df)\ncrs_info2 &lt;- st_crs(island_df)\ncrs_info1\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\ncrs_info2\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\n\n\n\n\nNote\n\n\n\nChanging the referencing system to Singapore national projected coordinate system for both Road and Island data.\n\n\n\nroad_sf &lt;- st_transform(road_df, crs = 3414)\nisland_sf &lt;- st_transform(island_df, crs = 3414)\n\n\n\n\n\n\n\nNote\n\n\n\nChanging the referencing system to Singapore national projected coordinate system for Grab data and assigning it to variable listings_sf.\n\n\n\nlistings_sf &lt;- st_as_sf(origin_df, \n                       coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\nglimpse(listings_sf)\n\nRows: 28,000\nColumns: 11\nGroups: trj_id [28,000]\n$ trj_id        &lt;chr&gt; \"70895\", \"21926\", \"47498\", \"18103\", \"41322\", \"64813\", \"8…\n$ driving_mode  &lt;chr&gt; \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", …\n$ osname        &lt;chr&gt; \"android\", \"android\", \"ios\", \"android\", \"android\", \"ios\"…\n$ pingtimestamp &lt;dttm&gt; 2019-04-08 00:09:26, 2019-04-08 00:09:48, 2019-04-08 00…\n$ speed         &lt;dbl&gt; 9.9546840, 11.0183750, 18.5645161, 0.4040553, 17.9400000…\n$ bearing       &lt;int&gt; 111, 75, 307, 159, 232, 106, 213, 179, 211, 107, 308, 29…\n$ accuracy      &lt;dbl&gt; 4.000, 4.000, 8.000, 3.000, 3.900, 10.000, 10.000, 4.000…\n$ weekday       &lt;ord&gt; Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon, M…\n$ start_hr      &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ day           &lt;fct&gt; 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,…\n$ geometry      &lt;POINT [m]&gt; POINT (20933.84 40231.63), POINT (31257.84 30407.3…\n\n\nRetrieve all roads within Singapore only\n\nsf_df &lt;- st_as_sf(road_sf, wkt = \"geometry\")\nroads_in_singapore &lt;- st_intersection(sf_df, island_sf)\n\n\n\n\n\n\n\nNote\n\n\n\nPreparing the following geospatial data layer in sf tibble data.frames.\n\n\nRoad layer within Singapore excluding outer islands.\n\ntibble1 &lt;- as_tibble(roads_in_singapore)\ntibble1\n\n# A tibble: 83,463 × 17\n   osm_id  code fclass name  ref   oneway maxspeed layer bridge tunnel SUBZONE_N\n   &lt;chr&gt;  &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;    \n 1 23946…  5122 resid… Rhu … &lt;NA&gt;  F            50     0 F      F      MARINA E…\n 2 49961…  5111 motor… East… ECP   F            70     1 F      F      MARINA E…\n 3 74722…  5111 motor… East… ECP   F            70     1 T      F      MARINA E…\n 4 11679…  5111 motor… Mari… MCE   F            80    -2 F      T      MARINA E…\n 5 11679…  5111 motor… Mari… MCE   F            80    -2 F      T      MARINA E…\n 6 12206…  5111 motor… East… ECP   F            70     1 T      F      MARINA E…\n 7 13138…  5111 motor… Mari… MCE   F            80    -2 F      T      MARINA E…\n 8 15081…  5141 servi… Bay … &lt;NA&gt;  B             0     0 F      F      MARINA E…\n 9 17376…  5111 motor… East… ECP   F            70     1 T      F      MARINA E…\n10 17471…  5152 cycle… Skyl… &lt;NA&gt;  B             0     0 F      F      MARINA E…\n# ℹ 83,453 more rows\n# ℹ 6 more variables: SUBZONE_C &lt;chr&gt;, PLN_AREA_N &lt;chr&gt;, PLN_AREA_C &lt;chr&gt;,\n#   REGION_N &lt;chr&gt;, REGION_C &lt;chr&gt;, geometry &lt;LINESTRING [m]&gt;\n\n\nSingapore boundary layer excluding outer islands\n\ntibble2 &lt;- as_tibble(island_df)\ntibble2\n\n# A tibble: 332 × 7\n   SUBZONE_N               SUBZONE_C PLN_AREA_N     PLN_AREA_C REGION_N REGION_C\n   &lt;chr&gt;                   &lt;chr&gt;     &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;   \n 1 MARINA EAST             MESZ01    MARINA EAST    ME         CENTRAL… CR      \n 2 INSTITUTION HILL        RVSZ05    RIVER VALLEY   RV         CENTRAL… CR      \n 3 ROBERTSON QUAY          SRSZ01    SINGAPORE RIV… SR         CENTRAL… CR      \n 4 JURONG ISLAND AND BUKOM WISZ01    WESTERN ISLAN… WI         WEST RE… WR      \n 5 FORT CANNING            MUSZ02    MUSEUM         MU         CENTRAL… CR      \n 6 MARINA EAST (MP)        MPSZ05    MARINE PARADE  MP         CENTRAL… CR      \n 7 SUDONG                  WISZ03    WESTERN ISLAN… WI         WEST RE… WR      \n 8 SEMAKAU                 WISZ02    WESTERN ISLAN… WI         WEST RE… WR      \n 9 SOUTHERN GROUP          SISZ02    SOUTHERN ISLA… SI         CENTRAL… CR      \n10 SENTOSA                 SISZ01    SOUTHERN ISLA… SI         CENTRAL… CR      \n# ℹ 322 more rows\n# ℹ 1 more variable: geometry &lt;MULTIPOLYGON [°]&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#mapping-the-geospatial-data-sets",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#mapping-the-geospatial-data-sets",
    "title": "Take-home Exercise 1",
    "section": "2.3 Mapping the geospatial data sets",
    "text": "2.3 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\nroads_in_singapore &lt;- st_transform(roads_in_singapore, crs = 3414)\n\nGrab Taxi Location Points\n\ntmap_mode(\"plot\")\ntm_shape(listings_sf) +\n  tm_dots()\n\n\n\n\nMaster Plan 2019 Planning Subzone Boundary with Grab Taxi Location Points\n\ntm_shape(island_sf) +\n  tm_polygons() +\ntm_shape(listings_sf) +\n  tm_dots()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "Take-home Exercise 1",
    "section": "3.1 Converting sf data frames to sp’s Spatial* class",
    "text": "3.1 Converting sf data frames to sp’s Spatial* class\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nisland &lt;- as_Spatial(island_sf)\nlistings &lt;- as_Spatial(listings_sf)\nroad &lt;- as_Spatial(roads_in_singapore)\n\n\nroad_as &lt;- read_rds(\"../../data/TakeHome/TakeHome_01/rds/as_road_df.rds\")\nisland_as &lt;- read_rds(\"../../data/TakeHome/TakeHome_01/rds/as_island_df.rds\")\nlistings_as &lt;- read_rds(\"../../data/TakeHome/TakeHome_01/rds/as_listings_df.rds\")\n\n\nisland_as\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 6\nnames       : SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  : ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  :    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION,       WR \n\n\n\nroad_as\n\nclass       : SpatialLinesDataFrame \nfeatures    : 83463 \nextent      : 3620.434, 55604.55, 23099.51, 50154.22  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 16\nnames       :     osm_id, code,   fclass,                                       name, ref, oneway, maxspeed, layer, bridge, tunnel, SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, ... \nmin values  : 1000098060, 5111, cycleway, 105 Henderson Crescent Lobby Drive-Through,   1,      B,        0,    -2,      F,      F, ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION, ... \nmax values  :  999921410, 5199,  unknown,                           Zubir Said Drive, TPE,      T,       90,     5,      T,      T,    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION, ... \n\n\n\nlistings_as\n\nclass       : SpatialPointsDataFrame \nfeatures    : 28000 \nextent      : 3628.243, 49845.23, 25198.14, 49689.64  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 10\nnames       : trj_id, driving_mode,  osname, pingtimestamp,            speed, bearing, accuracy, weekday, start_hr, day \nmin values  :     10,          car, android,    1554682166,               -1,       0,        1,     Fri,        0,  10 \nmax values  :   9984,          car,     ios,    1555889608, 30.9490566253662,     359,      728,     Wed,        9,   9"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Take-home Exercise 1",
    "section": "3.2 Converting the Spatial* class into generic sp format",
    "text": "3.2 Converting the Spatial* class into generic sp format\nSince spatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nisland_sp &lt;- as(island_as, \"SpatialPolygons\")\nroad_sp &lt;- as(road_as, \"SpatialPoints\")\n\n\nroad_sp &lt;- read_rds(\"../../data/TakeHome/TakeHome_01/rds/sp_road_df.rds\")\nisland_sp &lt;- read_rds(\"../../data/TakeHome/TakeHome_01/rds/sp_island_df.rds\")\n\n\nisland_sp\n\nclass       : SpatialPolygons \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nroad_sp\n\nclass       : SpatialPoints \nfeatures    : 286009 \nextent      : 3620.434, 55604.55, 23099.51, 50154.22  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Take-home Exercise 1",
    "section": "3.3 Converting the generic sp format into spatstat’s ppp format",
    "text": "3.3 Converting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nroad_ppp &lt;- as(road_sp, \"ppp\")\n\n\nplot(road_ppp)\n\n\n\n\n\nsummary(road_ppp)\n\nPlanar point pattern:  286009 points\nAverage intensity 0.0002033603 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [3620.43, 55604.55] x [23099.51, 50154.22] units\n                    (51980 x 27050 units)\nWindow area = 1406410000 square units\n\n\n\nlistings_ppp &lt;- as.ppp(listings_as)\n\n\nsummary(listings_ppp)\n\nMarked planar point pattern:  28000 points\nAverage intensity 2.473666e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nMark variables: trj_id, driving_mode, osname, pingtimestamp, speed, bearing, \naccuracy, weekday, start_hr, day\nSummary:\n    trj_id          driving_mode          osname         \n Length:28000       Length:28000       Length:28000      \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n pingtimestamp                        speed           bearing     \n Min.   :2019-04-08 00:09:26.00   Min.   :-1.000   Min.   :  0.0  \n 1st Qu.:2019-04-11 08:48:29.25   1st Qu.: 3.590   1st Qu.: 90.0  \n Median :2019-04-15 00:08:48.00   Median : 9.945   Median :179.0  \n Mean   :2019-04-14 21:29:59.93   Mean   : 9.566   Mean   :172.5  \n 3rd Qu.:2019-04-18 10:47:59.25   3rd Qu.:14.550   3rd Qu.:256.0  \n Max.   :2019-04-21 23:33:28.00   Max.   :30.949   Max.   :359.0  \n                                                                  \n    accuracy       weekday       start_hr          day       \n Min.   :  1.000   Sun:3983   9      : 2104   17     : 2012  \n 1st Qu.:  3.900   Mon:3975   10     : 2104   18     : 2008  \n Median :  6.000   Tue:4008   0      : 1941   12     : 2007  \n Mean   :  7.617   Wed:4016   1      : 1919   9      : 2004  \n 3rd Qu.: 10.000   Thu:4008   8      : 1541   16     : 2004  \n Max.   :728.000   Fri:4002   7      : 1539   13     : 2004  \n                   Sat:4008   (Other):16852   (Other):15961  \n\nWindow: rectangle = [3628.24, 49845.23] x [25198.14, 49689.64] units\n                    (46220 x 24490 units)\nWindow area = 1131920000 square units"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-owin-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-owin-object",
    "title": "Take-home Exercise 1",
    "section": "3.4 Creating owin object",
    "text": "3.4 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as(island_sp, \"owin\")\nplot(sg_owin)\n\n\n\n\n\nglimpse(summary(sg_owin))\n\nList of 10\n $ xrange      : num [1:2] 2668 56396\n $ yrange      : num [1:2] 15749 50256\n $ type        : chr \"polygonal\"\n $ area        : num 7.85e+08\n $ units       :List of 3\n  ..$ singular  : chr \"unit\"\n  ..$ plural    : chr \"units\"\n  ..$ multiplier: num 1\n  ..- attr(*, \"class\")= chr \"unitname\"\n $ areafraction: num 0.423\n $ npoly       : int 387\n $ areas       : num [1:387] 1.84e+06 3.93e+05 5.07e+05 3.29e+07 -3.79e-02 ...\n $ nvertices   : int [1:387] 299 165 239 1265 3 487 264 65 47 22 ...\n $ nhole       : int 13\n - attr(*, \"class\")= chr \"summary.owin\""
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#combining-point-events-object-and-owin-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#combining-point-events-object-and-owin-object",
    "title": "Take-home Exercise 1",
    "section": "3.5 Combining point events object and owin object",
    "text": "3.5 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract road events that are located within Singapore by using the code chunk below.\n\nislandSG_ppp_road = road_ppp[sg_owin]\n\n\nglimpse(summary(islandSG_ppp_road))\n\nList of 6\n $ is.marked  : logi FALSE\n $ n          : int 285700\n $ window     :List of 10\n  ..$ xrange      : num [1:2] 2668 56396\n  ..$ yrange      : num [1:2] 15749 50256\n  ..$ type        : chr \"polygonal\"\n  ..$ area        : num 7.85e+08\n  ..$ units       :List of 3\n  .. ..$ singular  : chr \"unit\"\n  .. ..$ plural    : chr \"units\"\n  .. ..$ multiplier: num 1\n  .. ..- attr(*, \"class\")= chr \"unitname\"\n  ..$ areafraction: num 0.423\n  ..$ npoly       : int 387\n  ..$ areas       : num [1:387] 1.84e+06 3.93e+05 5.07e+05 3.29e+07 -3.79e-02 ...\n  ..$ nvertices   : int [1:387] 299 165 239 1265 3 487 264 65 47 22 ...\n  ..$ nhole       : int 13\n  ..- attr(*, \"class\")= chr \"summary.owin\"\n $ intensity  : num 0.000364\n $ nduplicated: int 93372\n $ rounding   : num 3\n - attr(*, \"class\")= chr \"summary.ppp\""
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#handling-duplicated-points",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#handling-duplicated-points",
    "title": "Take-home Exercise 1",
    "section": "3.6 Handling duplicated points",
    "text": "3.6 Handling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(islandSG_ppp_road))\n\n[1] TRUE\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\n\n\nmultiplicity(islandSG_ppp_road)\n\n\n\n\n\n\n\nNote\n\n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\n\n\nsum(multiplicity(islandSG_ppp_road) &gt; 1)\n\n[1] 165793\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe output shows that there are 165793 duplicated point events.\nTo view the locations of these duplicate point events, we will plot both data.\n\n\nRoad data plot\n\ntmap_mode('plot')\ntm_shape(road_as) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\nGrab data plot\n\ntmap_mode('plot')\ntm_shape(listings_as) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space. The code chunk below implements the jittering approach.\n\n\n\nroad_ppp_jit &lt;- rjitter(road_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nany(duplicated(road_ppp_jit))\n\n[1] FALSE\n\n\n\nislandSG_ppp_road = road_ppp_jit[sg_owin]\nplot(islandSG_ppp_road)\n\n\n\n\n\nislandSG_ppp_grab = listings_ppp[sg_owin]\n\n\nglimpse(summary(islandSG_ppp_grab))\n\nList of 12\n $ is.marked     : logi TRUE\n $ n             : int 28000\n $ window        :List of 10\n  ..$ xrange      : num [1:2] 2668 56396\n  ..$ yrange      : num [1:2] 15749 50256\n  ..$ type        : chr \"polygonal\"\n  ..$ area        : num 7.85e+08\n  ..$ units       :List of 3\n  .. ..$ singular  : chr \"unit\"\n  .. ..$ plural    : chr \"units\"\n  .. ..$ multiplier: num 1\n  .. ..- attr(*, \"class\")= chr \"unitname\"\n  ..$ areafraction: num 0.423\n  ..$ npoly       : int 387\n  ..$ areas       : num [1:387] 1.84e+06 3.93e+05 5.07e+05 3.29e+07 -3.79e-02 ...\n  ..$ nvertices   : int [1:387] 299 165 239 1265 3 487 264 65 47 22 ...\n  ..$ nhole       : int 13\n  ..- attr(*, \"class\")= chr \"summary.owin\"\n $ intensity     : num 3.57e-05\n $ nduplicated   : int 0\n $ rounding      : num 3\n $ multiple.marks: logi TRUE\n $ marknames     : chr [1:10] \"trj_id\" \"driving_mode\" \"osname\" \"pingtimestamp\" ...\n $ is.numeric    : logi FALSE\n $ marktype      : chr \"dataframe\"\n $ is.multitype  : logi FALSE\n $ marks         : 'table' chr [1:7, 1:10] \"Length:28000      \" \"Class :character  \" \"Mode  :character  \" NA ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:7] \"\" \"\" \"\" \"\" ...\n  .. ..$ : chr [1:10] \"   trj_id\" \"driving_mode\" \"   osname\" \"pingtimestamp\" ...\n - attr(*, \"class\")= chr \"summary.ppp\""
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#computing-kernel-density-estimation-using-automatic-bandwidth-selection-method",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#computing-kernel-density-estimation-using-automatic-bandwidth-selection-method",
    "title": "Take-home Exercise 1",
    "section": "4.1 Computing kernel density estimation using automatic bandwidth selection method",
    "text": "4.1 Computing kernel density estimation using automatic bandwidth selection method\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_grab_bw &lt;- density(listings_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nkde_roadSG_bw &lt;- density(road_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nGrab data KDE plot\n\nplot(kde_grab_bw)\n\n\n\n\n\nbw1 &lt;- bw.diggle(listings_ppp)\nbw1\n\n   sigma \n10.52992 \n\n\nRoad data KDE plot\n\nplot(kde_roadSG_bw)\n\n\n\n\n\nbw2 &lt;- bw.diggle(road_ppp)\nbw2\n\n   sigma \n1.224168"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#rescalling-kde-values",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#rescalling-kde-values",
    "title": "Take-home Exercise 1",
    "section": "4.2 Rescalling KDE values",
    "text": "4.2 Rescalling KDE values\nIn the code chunk below, rescale() is used to covert the unit of measurement from meter to kilometer.\n\ngrab_ppp.km &lt;- rescale(listings_ppp, 1000, \"km\")\n\nGrab data rescaled KDE plot\n\nkde_grab.bw &lt;- density(grab_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_grab.bw)\n\n\n\n\n\nroad_ppp.km &lt;- rescale(road_ppp, 1000, \"km\")\n\nRoad data rescaled KDE plot\n\nkde_roadSG.bw &lt;- density(road_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_roadSG.bw)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-automatic-badwidth-methods",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-automatic-badwidth-methods",
    "title": "Take-home Exercise 1",
    "section": "4.3 Working with different automatic badwidth methods",
    "text": "4.3 Working with different automatic badwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth return by these automatic bandwidth calculation methods by using the code chunk below.\n\nbw.scott(grab_ppp.km)\n\n  sigma.x   sigma.y \n1.5926707 0.9389324 \n\n\n\nbw.diggle(grab_ppp.km)\n\n     sigma \n0.01052992 \n\n\nGrab data diggle & scott bandwidth plot\n\nkde_grab.scott &lt;- density(grab_ppp.km, \n                               sigma=bw.scott, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_grab.bw, main = \"bw.diggle\")\nplot(kde_grab.scott, main = \"bw.scott\")\n\n\n\n\n\nbw.scott(road_ppp.km)\n\n sigma.x  sigma.y \n1.090330 0.634362 \n\n\n\nbw.diggle(road_ppp.km)\n\n      sigma \n0.001224168 \n\n\nRoad data diggle & scott bandwidth plot\n\nkde_roadSG.scott &lt;- density(road_ppp.km, \n                               sigma=bw.scott, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_roadSG.bw, main = \"bw.diggle\")\nplot(kde_roadSG.scott, main = \"bw.scott\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-kde-output-into-grid-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-kde-output-into-grid-object",
    "title": "Take-home Exercise 1",
    "section": "4.4 Converting KDE output into grid object",
    "text": "4.4 Converting KDE output into grid object\nNow we convert it so that it is suitable for mapping purposes.\nGrab data grid object plot\n\ngridded_kde_grab_bw &lt;- as.SpatialGridDataFrame.im(kde_grab.bw)\nspplot(gridded_kde_grab_bw)\n\n\n\n\nRoad data grid object plot\n\ngridded_kde_roadSG_bw &lt;- as.SpatialGridDataFrame.im(kde_roadSG.bw)\nspplot(gridded_kde_roadSG_bw)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-gridded-output-into-raster",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-gridded-output-into-raster",
    "title": "Take-home Exercise 1",
    "section": "4.5 Converting gridded output into raster",
    "text": "4.5 Converting gridded output into raster\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_kde_grab_bw_raster &lt;- raster(gridded_kde_grab_bw)\n\n\nkde_kde_roadSG_bw_raster &lt;- raster(gridded_kde_roadSG_bw)\n\nLet us take a look at the properties of Grab data RasterLayer.\n\nkde_kde_grab_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.3610702, 0.1913398  (x, y)\nextent     : 3.628243, 49.84523, 25.19814, 49.68964  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -5.496863e-13, 2808.049  (min, max)\n\n\nLet us take a look at the properties of Road data RasterLayer.\n\nkde_kde_roadSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4061259, 0.2113649  (x, y)\nextent     : 3.620434, 55.60455, 23.09951, 50.15422  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -1.013988e-12, 4997.626  (min, max)\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that both the crs property is NA."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#assigning-projection-systems",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#assigning-projection-systems",
    "title": "Take-home Exercise 1",
    "section": "4.6 Assigning projection systems",
    "text": "4.6 Assigning projection systems\nThe code chunk below will be used to include the CRS information on both data RasterLayer.\n\nprojection(kde_kde_grab_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_kde_grab_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.3610702, 0.1913398  (x, y)\nextent     : 3.628243, 49.84523, 25.19814, 49.68964  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -5.496863e-13, 2808.049  (min, max)\n\n\n\nprojection(kde_kde_roadSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_kde_roadSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4061259, 0.2113649  (x, y)\nextent     : 3.620434, 55.60455, 23.09951, 50.15422  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.013988e-12, 4997.626  (min, max)\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the crs property is completed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-study-area",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-study-area",
    "title": "Take-home Exercise 1",
    "section": "6.1 Extracting study area",
    "text": "6.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas at Punggol, Tampines, Chua Chu Kang and Jurong West.\n\npung &lt;- islandMe %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\npung &lt;- pung%&gt;%\n  st_union()\npung &lt;- st_make_valid(pung)\n\n\ntamp &lt;- islandMe %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\ntamp &lt;- tamp%&gt;%\n  st_union()\ntamp &lt;- st_make_valid(tamp)\n\n\ncck &lt;- islandMe %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\ncck &lt;- cck%&gt;%\n  st_union()\ncck &lt;- st_make_valid(cck)\n\n\njw &lt;- islandMe %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\njw &lt;- jw%&gt;%\n  st_union()\njw &lt;- st_make_valid(jw)\n\n\npung &lt;- st_transform(pung, crs = 3414)\ntamp &lt;- st_transform(tamp, crs = 3414)\ncck &lt;- st_transform(cck, crs = 3414)\njw &lt;- st_transform(jw, crs = 3414)\n\nRetrieving roads within target planning areas\n\npung_roads &lt;- st_intersection(roads_in_singapore, pung)\ntamp_roads &lt;- st_intersection(roads_in_singapore, tamp)\ncck_roads &lt;- st_intersection(roads_in_singapore, cck)\njw_roads &lt;- st_intersection(roads_in_singapore, jw)\n\nPlotting target planning areas\n\npar(mfrow=c(2,2))\nplot(pung, main = \"Punggol\")\nplot(tamp, main = \"Tampines\")\nplot(cck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\nThe code chunk below is used to plot the roads of these four study areas.\n\ntmap_mode('plot')\ntmap_arrange(tm_shape(pung_roads) +\n               tm_lines(col = \"red\") +\n               tm_layout(title = \"Punggol\", title.size = 0.8),\n             tm_shape(tamp_roads) +\n               tm_lines(col = \"blue\") +\n               tm_layout(title = \"Tampines\", title.size = 0.8), \n             tm_shape(cck_roads) +\n               tm_lines(col = \"green\") +\n               tm_layout(title = \"Choa Chu Kang\", title.size = 0.8),\n             tm_shape(jw_roads) +\n               tm_lines(col = \"orange\") +\n               tm_layout(title = \"Jurong West\", title.size = 0.8),\n             asp=2, ncol=2)\n\n\n\n\nConverting them to linestring format\n\npung_roads &lt;- st_cast(pung_roads, \"LINESTRING\")\ntamp_roads &lt;- st_cast(tamp_roads, \"LINESTRING\")\ncck_roads &lt;- st_cast(cck_roads, \"LINESTRING\")\njw_roads &lt;- st_cast(jw_roads, \"LINESTRING\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-the-lixels-objects",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-the-lixels-objects",
    "title": "Take-home Exercise 1",
    "section": "6.2 Preparing the lixels objects",
    "text": "6.2 Preparing the lixels objects\nBefore computing NetKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels_pung &lt;- lixelize_lines(pung_roads, \n                         700, \n                         mindist = 350)\nlixels_tamp &lt;- lixelize_lines(tamp_roads, \n                         700, \n                         mindist = 350)\nlixels_cck &lt;- lixelize_lines(cck_roads, \n                         700, \n                         mindist = 350)\nlixels_jw &lt;- lixelize_lines(jw_roads, \n                         700, \n                         mindist = 350)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#generating-line-centre-points",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#generating-line-centre-points",
    "title": "Take-home Exercise 1",
    "section": "6.3 Generating line centre points",
    "text": "6.3 Generating line centre points\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\nsamples_pung &lt;- lines_center(lixels_pung)\nsamples_tamp &lt;- lines_center(lixels_tamp)\nsamples_cck &lt;- lines_center(lixels_cck)\nsamples_jw &lt;- lines_center(lixels_jw)\n\n\norigin_pung = st_intersection(listings_sf, pung)\norigin_tamp = st_intersection(listings_sf, tamp)\norigin_cck = st_intersection(listings_sf, cck)\norigin_jw = st_intersection(listings_sf, jw)\n\nTo visualise the geospatial data with high cartographic quality and interactive manner, the mapping function of tmap package can be used as shown in the code chunk below.\n\nPunggolTampinesChoa Chu KangJurong West\n\n\n\ntmap_mode('view')\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(pung_roads) +\n  tm_lines(col = \"red\") +\n  tm_shape(origin_pung) + \n  tm_dots()\n\n\n\n\n\ntmap_mode('plot')\n\n\n\n\ntmap_mode('view')\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(tamp_roads) +\n  tm_lines(col = \"blue\") +\n  tm_shape(origin_tamp) + \n  tm_dots()\n\n\n\n\n\ntmap_mode('plot')\n\n\n\n\ntmap_mode('view')\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(cck_roads) +\n  tm_lines(col = \"green\") +\n  tm_shape(origin_cck) + \n  tm_dots()\n\n\n\n\n\ntmap_mode('plot')\n\n\n\n\ntmap_mode('view')\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(jw_roads) +\n  tm_lines(col = \"orange\") +\n  tm_shape(origin_jw) + \n  tm_dots()\n\n\n\n\n\ntmap_mode('plot')\n\n\n\n\nThe points are located at center of the line based on the length of the line."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-netkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-netkde",
    "title": "Take-home Exercise 1",
    "section": "6.4 Performing NetKDE",
    "text": "6.4 Performing NetKDE\nWe are ready to compute the NetKDE by using the code chunk below.\n\nPunggolTampinesChoa Chu KangJurong West\n\n\n\ndensities_pung &lt;- nkde(pung_roads, \n                  events = origin_pung,\n                  w = rep(1,nrow(origin_pung)),\n                  samples = samples_pung,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\ndensities_tamp &lt;- nkde(tamp_roads, \n                  events = origin_tamp,\n                  w = rep(1,nrow(origin_tamp)),\n                  samples = samples_tamp,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\ndensities_cck &lt;- nkde(cck_roads, \n                  events = origin_cck,\n                  w = rep(1,nrow(origin_cck)),\n                  samples = samples_cck,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\ndensities_jw &lt;- nkde(jw_roads, \n                  events = origin_jw,\n                  w = rep(1,nrow(origin_jw)),\n                  samples = samples_jw,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\nBefore we can visualise the NetKDE values, the code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\n\n\n\n\n\nNote\n\n\n\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. The code chunk below is used to resale the density values from number of events per meter to number of events per kilometer.\n\n\n\nPunggolTampinesChoa Chu KangJurong West\n\n\n\nsamples_pung$density &lt;- densities_pung\nlixels_pung$density &lt;- densities_pung\n# rescaling to help the mapping\nsamples_pung$density &lt;- samples_pung$density*1000\nlixels_pung$density &lt;- lixels_pung$density*1000\n\n\n\n\nsamples_tamp$density &lt;- densities_tamp\nlixels_tamp$density &lt;- densities_tamp\n# rescaling to help the mapping\nsamples_tamp$density &lt;- samples_tamp$density*1000\nlixels_tamp$density &lt;- lixels_tamp$density*1000\n\n\n\n\nsamples_cck$density &lt;- densities_cck\nlixels_cck$density &lt;- densities_cck\n# rescaling to help the mapping\nsamples_cck$density &lt;- samples_cck$density*1000\nlixels_cck$density &lt;- lixels_cck$density*1000\n\n\n\n\nsamples_jw$density &lt;- densities_jw\nlixels_jw$density &lt;- densities_jw\n# rescaling to help the mapping\nsamples_jw$density &lt;- samples_jw$density*1000\nlixels_jw$density &lt;- lixels_jw$density*1000\n\n\n\n\nThe code below uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation.\n\nPunggolTampinesChoa Chu KangJurong West\n\n\n\ntmap_mode('plot')\ntm_shape(lixels_pung)+\n  tm_lines(col=\"density\")+\ntm_shape(origin_pung)+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode('plot')\ntm_shape(lixels_tamp)+\n  tm_lines(col=\"density\")+\ntm_shape(origin_tamp)+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode('plot')\ntm_shape(lixels_cck)+\n  tm_lines(col=\"density\")+\ntm_shape(origin_cck)+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode('plot')\ntm_shape(lixels_jw)+\n  tm_lines(col=\"density\")+\ntm_shape(origin_jw)+\n  tm_dots()\n\n\n\n\n\n\n\nThe interactive map above effectively reveals road segments (darker color) with relatively higher density of Grab taxi location points than road segments with relatively lower density of Grab taxi location points (lighter color)."
  }
]